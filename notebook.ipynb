{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the rank of Starcraft II players\n",
    "\n",
    "**Ethan Shapiro**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "**Our Questions:** Can we predict a Starcraft player's rank based on their past ranked performance? If so, what information is useful and or will be useful to collect for future prediction?\n",
    "\n",
    "**Type of Prediction Problem:** We're doing a multiclass classification on the player's rank.\n",
    "\n",
    "**Response Variable:** Finding a solution to these problems I see could help us a few ways:\n",
    "1. Placing veteran players in the new ranked season\n",
    "2. Placing new players into their first ranked league\n",
    "3. Working in conjunction with another model to adjust ranks (ranked reset, rank inflation adjustments, etc.)\n",
    "\n",
    "**Metric:** I chose accuracy for the model because we want to weigh false positives and false negatives equally in our outcomes.\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Baseline Model\n",
    "For our baseline model, we chose to use a **Decision Tree Classifier**.\n",
    "\n",
    "We included these features:\n",
    " - **Officer Age at the incident (mos_age_incident)**\n",
    "    - Type: Quantitative\n",
    "    - Encoding: None\n",
    " - **Officer Ethnicity (mos_ethnicity)**\n",
    "    - Type: Categorical\n",
    "    - Encoding: One Hot Encoding\n",
    " - **Officer Gender (mos_gender)**\n",
    "    - Type: Categorical\n",
    "    - Encoding: One Hot Encoding\n",
    " - **Complainant Ethnicity (complainant_ethnicity)**\n",
    "    - Type: Categorical\n",
    "    - Encoding: One Hot Encoding\n",
    " - **Complainant Gender (complainant_gender)**\n",
    "    - Type: Categorical\n",
    "    - Encoding: One Hot Encoding\n",
    " - **Complainant Age (complainant_age_incident)**\n",
    "    - Type: Quantitative\n",
    "    - Encoding: None\n",
    " - **Type of Complaint (fado_type)**\n",
    "    - Type: Categorical\n",
    "    - Encoding: One Hot Encoding\n",
    "    \n",
    "We were trying to predict: **Outcome of Complaint (complaint_outcome)**\n",
    "\n",
    "Our Basic Model's performance was:\n",
    " - Test accuracy: ~0.4944\n",
    " - Test precision: ~0.4628\n",
    " \n",
    "We don't believe our model is good because it doesn't do significantly better than simply randomly guessing an outcome (which would be ~33%).<br>\n",
    "There is no point to telling a complainant a possible outcome if we are not even 50% sure of our prediction.\n",
    "\n",
    "### Final Model\n",
    "For our final model, we stuck with a **Decision Tree Classifier**.\n",
    "\n",
    "We feature engineered the following:\n",
    " - **Officer is a Minority**\n",
    "    - *Type:* Categorical/Binary\n",
    "    - *Encoding:* Returning any ethnicity non-white as a 1 and white as a 0.\n",
    "    - *Why it's a good fit:* We believe there could be bias in the CCRB decision process based on ethnicity. Therefore, knowing if an officer is a minority might give information about the outcome of the complaint.\n",
    " - **Complainant is a Minority**\n",
    "    - *Type:* Categorical/Binary\n",
    "    - *Encoding:* Returning any ethnicity non-white as a 1 and white as a 0.\n",
    "    - *Why it's a good fit:* We believe there could be bias in the CCRB decision process based on ethnicity. Therefore, knowing if a complainant is a minority might give information about the outcome of the complaint.\n",
    " - **Officer is a High Rank**\n",
    "    - *Type:* Categorical/Binary\n",
    "    - *Encoding:* Returning 1 for Deputy Inspector, Inspector, and Chief/other high ranks. Returning 0 otherwise.\n",
    "    - *Why it's a good fit:* Higher ranking officers might have more favorable outcomes than lower ranking officers. Therefore, knowing if the rank is a high rank can help us predict the outcome.\n",
    " - **General Allegation Type**\n",
    "    - *Type:* Categorical\n",
    "    - *Encoding:* We take the original 76 unique allegation types and categorize them into 11 general groups. Then, we were able to One Hot Encode them.\n",
    "    - *Why it's a good fit:* We believe the severity of the complaint will give information about the outcome of the complaint. I.E. More severe complaint allegations might be more likely to be Substantiated and vice-versa.\n",
    " - **General Outcome Type**\n",
    "    - *Type:* Categorical/Ordinal\n",
    "    - *Encoding:* We generalized the original outcome types into three major types: Arrest, Summons, or No Arrest. Then, we ordinally encoded it, making Arrest the most severe outcome, followed by Summons, and then No Arrest.\n",
    "    - *Why it's a good fit:* We believe the outcome of the Officer and Complainant interaction can influence the decision of the CCRB. I.E. If someone is arrested during the interaction, their complaint might be out of spite and not necessarily true.\n",
    "\n",
    "After creating these features, we ran a **GridSearchCV** with a **Decision Tree**, **5 folds**, and fitted on **75%** of the original data. We ended up with the following best hyperparameters:\n",
    " - criterion: entropy\n",
    " - max_depth: 12\n",
    " - min_samples_split: 15\n",
    "\n",
    "Our Final Model's performance was:\n",
    " - Test accuracy: ~0.5349\n",
    " - Test precision: ~0.5408\n",
    "\n",
    "This means our model improved its accuracy by ~4.05% and its precision by ~7.80%.\n",
    "\n",
    "### Fairness Analysis\n",
    "\n",
    "We ran a permutation Tests to test our model's **precision** of Minority vs. Non-Minority Complainants with the following hypotheses:\n",
    "\n",
    "<b>Null Hypothesis:</b> Our model is fair. Its precision for minorities and non-minorities are roughly the same, and differences are due to random chance.\n",
    "\n",
    "<b>Alternative Hypothesis:</b> Our model is unfair. Its precision for minorities is better than for minorities than non-minorities.\n",
    "\n",
    "<b>Evaluation Metric:</b> Precision\n",
    "\n",
    "<b>Our signifcance value:</b> 0.05\n",
    "\n",
    "With a p-value = 0.013 < 0.05, we reject the null hypothesis and say that our model is unfair.\n",
    "Our model has worse precision for complainants that are non-minorities than it does for minorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
